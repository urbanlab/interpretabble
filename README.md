## InterpretaꓭBle

---

### Running

Launch the OpenFramework program then, click onto "Load model" and choose the accurate model (named final on computer)

Take care of opacity and thresold, for having a clear line of sight (no dark pixels on the drawing zone) and no auto-focusing all the time (change opacity for that)

After you setted up all of the parameters, launch the translating server with this command, executed at the root of the
project, using a terminal.


```
node Translations/translator/translate.js
```

Then, open *(CHROME ONLY)* the address:
```
localhost:9092
```

You can now talk into the microphone, search for scenario and display all of that.

In case of bug, relaunch the OpenFramework program.

### Working

For the device to work, you must draw something on the drawing zone, for it to oper.

If what you draw continue switching between labels, remember that the Web site (localhost:9092) can help you choose a fixed scenario.

In other case, you can talk for it to detect that you speech, however you must before choose the language you are talking in.

Therefore, it will translate what you've said in the language you specified.

### Author list.

Chloé Angeloni (Designer teammate)

Elodie Lorthios (Designer teammate)

Maureen Troel (Designer teammate)

Marco Alghisi (Designer teammate)

Martial Geoffre-Rouland (Technician teammate)

Thomas Nicollet (Technician teammate)

Jacques Marques (Technician teammate)

### Special credits

ERASME Urban Lab for permitting us to achieve this projects

Martial Geoffre-Rouland for caming up with a B-plan 
